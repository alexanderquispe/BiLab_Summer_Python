{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#ASSIGNMENT 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!pip install pyreadstat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!pip install savReaderWriter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import os\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import pyreadstat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rec_1 = pyreadstat.read_sav('/REC0111.sav')\n",
    "\n",
    "print(rec_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rec_2 = pyreadstat.read_sav(r'/RE223132.sav')\n",
    "\n",
    "print(rec_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rec_3 = pyreadstat.read_sav('/RE516171.sav')\n",
    "\n",
    "print(rec_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "file_paths = [\n",
    "    '/REC0111.sav',\n",
    "    '/RE223132.sav',\n",
    "    '/RE516171.sav'\n",
    "]\n",
    "\n",
    "# Define names for imported files and labels\n",
    "file_names = ['rec_1', 'rec_2', 'rec_3']\n",
    "var_labels = ['var_labels1', 'var_labels2', 'var_labels3']\n",
    "value_labels = ['value_labels1', 'value_labels2', 'value_labels3']\n",
    "\n",
    "# Initialize dictionaries to store dataframes and labels\n",
    "dataframes = {}\n",
    "variable_labels = {}\n",
    "value_labels_dict = {}\n",
    "\n",
    "# Loop through the files\n",
    "for i, file_path in enumerate(file_paths):\n",
    "    # Read the SPSS file\n",
    "    df, meta = pyreadstat.read_sav(file_path)\n",
    "\n",
    "    # Store the dataframe\n",
    "    dataframes[file_names[i]] = df\n",
    "\n",
    "    # Store variable labels\n",
    "    variable_labels[var_labels[i]] = meta.column_labels\n",
    "\n",
    "    # Store value labels\n",
    "    value_labels_dict[value_labels[i]] = meta.variable_value_labels\n",
    "\n",
    "# Access the imported data and labels\n",
    "rec_1 = dataframes['rec_1']\n",
    "var_labels1 = variable_labels['var_labels1']\n",
    "value_labels1 = value_labels_dict['value_labels1']\n",
    "\n",
    "rec_2 = dataframes['rec_2']\n",
    "var_labels2 = variable_labels['var_labels2']\n",
    "value_labels2 = value_labels_dict['value_labels2']\n",
    "\n",
    "rec_3 = dataframes['rec_3']\n",
    "var_labels3 = variable_labels['var_labels3']\n",
    "value_labels3 = value_labels_dict['value_labels3']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print (\"rec_1 DataFrame:\")\n",
    "rec_1.head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(\"\\nVariable Labels for rec_1:\")\n",
    "var_labels1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "columns_rec1 = ['CASEID', 'V000', 'V001', 'V002', 'V003', 'V004', 'V007', 'V008', 'V009', 'V010', 'V011', 'V012', 'V024', 'V102', 'V120', 'V121', 'V122', 'V123', 'V124', 'V125', 'V127', 'V133']\n",
    "columns_rec2 = ['CASEID', 'V201', 'V218', 'V301', 'V302', 'V323', 'V323A', 'V325A', 'V326', 'V327', 'V337', 'V359', 'V360', 'V361', 'V362', 'V363', 'V364', 'V367', 'V372', 'V372A', 'V375A', 'V376', 'V376A', 'V379', 'V380']\n",
    "columns_rec3 = ['CASEID', 'V501', 'V502', 'V503', 'V504', 'V505', 'V506', 'V507', 'V508', 'V509', 'V510', 'V511', 'V512', 'V513', 'V525', 'V613', 'V714', 'V715']\n",
    "\n",
    "rec1_1 = rec_1.loc[:, columns_rec1]\n",
    "rec2_1 = rec_2.loc[:, columns_rec2]\n",
    "rec3_1 = rec_3.loc[:, columns_rec3]\n",
    "\n",
    "print (rec1_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print (rec2_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print (rec3_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select columns for rec1\n",
    "selected_columns_rec1 = [\n",
    "    'CASEID', 'V000', 'V001', 'V002', 'V003', 'V004', 'V007', 'V008', 'V009', 'V010',\n",
    "    'V011', 'V012', 'V024', 'V102', 'V120', 'V121', 'V122', 'V123', 'V124', 'V125', 'V127', 'V133'\n",
    "]\n",
    "\n",
    "# Create a new dataframe for rec1 with selected columns\n",
    "rec1_1 = rec_1.loc[:, selected_columns_rec1]\n",
    "\n",
    "# Update the variable labels object for rec1\n",
    "new_var_labels1 = variable_labels['var_labels1'][:len(selected_columns_rec1)]\n",
    "\n",
    "# Update the value labels object for rec1\n",
    "new_value_labels1 = {col: value_labels1.get(col, {}) for col in selected_columns_rec1}\n",
    "\n",
    "# Update the dataframes and labels dictionaries\n",
    "dataframes['rec1_1'] = rec1_1\n",
    "variable_labels['new_var_labels1'] = new_var_labels1\n",
    "value_labels_dict['new_value_labels1'] = new_value_labels1\n",
    "\n",
    "print (rec1_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select columns for rec2\n",
    "selected_columns_rec2 = [\n",
    "    'CASEID', 'V201', 'V218', 'V301', 'V302', 'V323', 'V323A', 'V325A', 'V326', 'V327',\n",
    "    'V337', 'V359', 'V360', 'V361', 'V362', 'V363', 'V364', 'V367', 'V372', 'V372A',\n",
    "    'V375A', 'V376', 'V376A', 'V379', 'V380'\n",
    "]\n",
    "\n",
    "## Create a new dataframe for rec1 with selected columns\n",
    "rec2_1 = rec_2.loc[:, selected_columns_rec2]\n",
    "\n",
    "## Update the variable labels object for rec1\n",
    "new_var_labels2 = variable_labels['var_labels2'][:len(selected_columns_rec2)]\n",
    "\n",
    "## Update the value labels object for rec1\n",
    "new_value_labels2 = {col: value_labels2.get(col, {}) for col in selected_columns_rec2}\n",
    "\n",
    "## Update the dataframes and labels dictionaries\n",
    "dataframes['rec2_1'] = rec2_1\n",
    "variable_labels['new_var_labels2'] = new_var_labels2\n",
    "value_labels_dict['new_value_labels2'] = new_value_labels2\n",
    "\n",
    "print (rec2_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select columns for rec3\n",
    "selected_columns_rec3 = [\n",
    "    'CASEID', 'V501', 'V502', 'V503', 'V504', 'V505', 'V506', 'V507', 'V508', 'V509',\n",
    "    'V510', 'V511', 'V512', 'V513', 'V525', 'V613', 'V714', 'V715'\n",
    "]\n",
    "\n",
    "# Create a new dataframe for rec1 with selected columns\n",
    "rec3_1 = rec_3.loc[:, selected_columns_rec3]\n",
    "\n",
    "# Update the variable labels object for rec1\n",
    "new_var_labels3 = variable_labels['var_labels3'][:len(selected_columns_rec3)]\n",
    "\n",
    "# Update the value labels object for rec1\n",
    "new_value_labels3 = {col: value_labels3.get(col, {}) for col in selected_columns_rec3}\n",
    "\n",
    "# Update the dataframes and labels dictionaries\n",
    "dataframes['rec3_1'] = rec3_1\n",
    "variable_labels['new_var_labels3'] = new_var_labels3\n",
    "value_labels_dict['new_value_labels3'] = new_value_labels3\n",
    "\n",
    "print(rec3_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Generate a new column for rec1_1 named as \"year\"\n",
    "#Use loc to add a column\n",
    "rec1_1.loc[:, 'year'] = 2019\n",
    "\n",
    "# We must update variable labels dictionary\n",
    "new_var_labels1.append({'year': \"Year of the survey\"})\n",
    "\n",
    "print(rec1_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4\n",
    "#merge rec1_1, rec2_1 and rec3_1 using CASEID\n",
    "#use a method chaining to merge the dataframes successively. This for performing a intern joins.\n",
    "endes_2019 = pd.merge(rec1_1, rec2_1, on ='CASEID').merge(rec3_1, on ='CASEID')\n",
    "print(endes_2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "## Exercise 5\n",
    "#Unifing all the new_var_labels in one object and new_value_labels in another one object.\n",
    "var_labels = [new_var_labels1]\n",
    "var_labels.extend(new_var_labels2)\n",
    "var_labels.extend(new_var_labels3)\n",
    "var_labels\n",
    "\n",
    "\n",
    "#Name these two objects as var_labels and value_labels.\n",
    "value_labels = [new_value_labels1]\n",
    "value_labels.extend(new_value_labels2)\n",
    "value_labels.extend(new_value_labels3)\n",
    "value_labels\n",
    "\n",
    "\n",
    "#Generate new attributes for endes_2019 that is named as var_labels and value_labels.\n",
    "#Using update\n",
    "endes_2019.update({'var_labels': var_labels, 'value_labels': value_labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "##This code snippet performs statistical calculations on specific columns of interest in a DataFrame named endes_2019, and then creates a new DataFrame (stats_df) to organize and display the calculated statistics.\n",
    "columns_of_interest = ['V201', 'V613', 'V715', 'V511']\n",
    "\n",
    "# Calculate statistics individually\n",
    "min_values = endes_2019[columns_of_interest].min()\n",
    "max_values = endes_2019[columns_of_interest].max()\n",
    "mean_values = endes_2019[columns_of_interest].mean()\n",
    "n_obs_values = endes_2019[columns_of_interest].count()\n",
    "n_missing_values = endes_2019[columns_of_interest].isnull().sum()\n",
    "\n",
    "# Create a DataFrame with calculated statistics\n",
    "stats_df = pd.DataFrame({\n",
    "    'Variables': columns_of_interest,\n",
    "    'Min': min_values,\n",
    "    'Max': max_values,\n",
    "    'Mean': mean_values,\n",
    "    'N_obs': n_obs_values,\n",
    "    'N_missing': n_missing_values\n",
    "})\n",
    "\n",
    "# Sort by the number of missing rows\n",
    "stats_df = stats_df.sort_values(by='N_missing')\n",
    "\n",
    "# Reset index to make 'Variables' a regular column\n",
    "stats_df = stats_df.reset_index(drop=True)\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#Exercise 7\n",
    "##This code snippet is performing a series of operations on a DataFrame named endes_2019\n",
    "# Select key columns\n",
    "key_columns = ['V201', 'V613', 'V715', 'V511']\n",
    "\n",
    "# Group by year and department and calculate average\n",
    "mean_key_vars = endes_2019.groupby(['year', 'V024'])[key_columns].mean().reset_index()\n",
    "\n",
    "# Rename columns\n",
    "mean_key_vars.columns = ['year', 'department', 'mean_total_children', 'mean_ideal_children', 'mean_hb_yr_educ', 'mean_first_marriage']\n",
    "\n",
    "# Display the result\n",
    "mean_key_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#Exercise 8\n",
    "##This code snippet is reshaping the DataFrame mean_key_vars using the pd.melt()\n",
    "reshape_mean_key_vars = pd.melt(mean_key_vars, id_vars=['department'], var_name='variables', value_name='values')\n",
    "reshape_mean_key_vars\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#Exercice 9\n",
    "9\n",
    "key_vars = [\"V201\", \"V613\", \"V715\", \"V511\"]\n",
    "#Agrupar DataFrame por \"year\" and \"department\" \n",
    "mean_key_vars = endes_data_2015_2019.groupby([\"year\", \"V024\"])[key_vars].mean().reset_index()\n",
    "#Luego, calcular columnas especiales\n",
    "mean_key_vars = mean_key_vars.round(2)\n",
    "#Renombrarlas\n",
    "mean_key_vars = mean_key_vars.rename(columns={\"V201\": \"mean_total_children\",\"V613\": \"mean_ideal_children\",\"V715\": \"mean_hb_yr_educ\",\"V511\":\"mean_first_marriage\"})\n",
    "mean_key_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#10\n",
    "endes_data_2015_2019 = endes_data_2015_2019.rename(columns={'V024': 'dpto'})\n",
    "#First, identify the common columns for merging\n",
    "mean_key_vars = mean_key_vars.rename(columns={'V024': 'dpto'})\n",
    "#We use merge to combine the DataFrames\n",
    "final_result = pd.merge(endes_data_2015_2019, mean_key_vars, on=['year', 'dpto'], how='left')\n",
    "final_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
