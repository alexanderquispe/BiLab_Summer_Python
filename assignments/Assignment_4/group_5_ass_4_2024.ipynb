{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Assignment 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyreadstat in c:\\users\\usuario\\anaconda3\\lib\\site-packages (1.2.6)\n",
      "Requirement already satisfied: pandas>=1.2.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from pyreadstat) (2.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from pandas>=1.2.0->pyreadstat) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from pandas>=1.2.0->pyreadstat) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from pandas>=1.2.0->pyreadstat) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from pandas>=1.2.0->pyreadstat) (1.24.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=1.2.0->pyreadstat) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyreadstat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "import pyreadstat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Import the `REC0111.sav`, `RE223132.sav` and `RE516171.sav` files and their variables and values labels from this path `\"../../_data/endes/2019\"`. The name of imported files should be named as `rec_1`, `rec_2` and `rec_3` for files `REC0111.sav`, `RE223132.sav` and `RE516171.sav` respectively. The name of the variable and value labels should be `var_labels1` and `value_labels1` for `rec1`, `var_labels2` and `value_labels2` for `rec2`, and `var_labels3` and `value_labels3` for `rec3`. **Hint: See the section 3.3.4 of [the lecture 3](https://github.com/alexanderquispe/Diplomado_PUCP/blob/main/Lecture_3/Lecture_3.ipynb)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we are accessing the file paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = [\n",
    "    \"../../_data/endes/2019/REC0111.sav\",\n",
    "    \"../../_data/endes/2019/RE223132.sav\",\n",
    "    \"../../_data/endes/2019/RE516171.sav\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we are designating the names for the DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_names = ['rec_1', 'rec_2', 'rec_3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we are designating the names for the variable and value labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_labels_names = ['var_labels1', 'var_labels2', 'var_labels3']\n",
    "value_labels_names = ['value_labels1', 'value_labels2', 'value_labels3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we are creating the dictionaries to store DataFrames and tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = {}\n",
    "var_labels = {}\n",
    "value_labels = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we are importing and assigning names using for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file_path, df_name, var_name, value_name in zip(file_paths, dataframe_names, var_labels_names, value_labels_names):\n",
    "    df, meta = pyreadstat.read_sav(file_path, apply_value_formats=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we are assigning names to the variables and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "    df.name = df_name\n",
    "    var_labels[var_name] = meta.column_labels\n",
    "    value_labels[value_name] = meta.variable_value_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we are storing DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "    dataframes[df_name] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Select the following columns for each data set:\n",
    "|Data|Columns|\n",
    "|---|---|\n",
    "|rec1| CASEID, V000, V001, V002, V003, V004, V007, V008, V009, V010, V011, V012, V024, V102, V120, V121, V122, V123, V124, V125, V127, V133 |\n",
    "|rec2| CASEID, V201, V218, V301, V302, V323, V323A, V325A, V326, V327, V337, V359, V360, V361, V362, V363, V364, V367, V372, V372A, V375A, V376, V376A, V379, V380 |\n",
    "|rec3| CASEID, V501, V502, V503, V504, V505, V506, V507, V508, V509, V510, V511, V512, V513, V525, V613, V714, V715 |\n",
    "\n",
    "\n",
    "Additioanlly, you should update the variables and value labels objects. They must have information only for the selected columns. The new dataframes should be name as `rec1_1`, `rec2_1`, and `rec3_1`. The new varible labels objects should be named as `new_var_labels1`, `new_var_labels2`, and `new_var_labels3`. The new value labels objects should be named as `new_value_labels1`, `new_value_labels2`, and `new_value_labels3` **Hint: Use the `loc` and column names to filter, `for loop`,   and [this link](https://stackoverflow.com/questions/3420122/filter-dict-to-contain-only-certain-keys) to update the var and value dictionary.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we are accessing the paths of the desired files and names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = [\"../../_data/endes/2019/REC0111.sav\", \"../../_data/endes/2019/RE223132.sav\", \"../../_data/endes/2019/RE516171.sav\"]\n",
    "dataframe_names = [\"rec_1\", \"rec_2\", \"rec_3\"]\n",
    "var_labels_names = [\"new_var_labels1\", \"new_var_labels2\", \"new_var_labels3\"]\n",
    "value_labels_names = [\"new_value_labels1\", \"new_value_labels2\", \"new_value_labels3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we are creating dictionaries to store the DataFrames and tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = {}\n",
    "var_labels = {}\n",
    "value_labels = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we are reading the sav file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file_path, df_name, var_name, value_name in zip(file_paths, dataframe_names, var_labels_names, value_labels_names):\n",
    "    \n",
    "    df, meta = pyreadstat.read_sav(file_path, apply_value_formats=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we are printing the columns available in the original data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Columnas disponibles en rec_3:\n",
      "Index(['ID1', 'CASEID', 'V501', 'V502', 'V503', 'V504', 'V505', 'V506', 'V507',\n",
      "       'V508', 'V509', 'V510', 'V511', 'V512', 'V513', 'V525', 'V527', 'V528',\n",
      "       'V529', 'V530', 'V531', 'V532', 'V535', 'V536', 'V537', 'V538', 'V539',\n",
      "       'V540', 'V541', 'V602', 'V603', 'V604', 'V605', 'V613', 'V614', 'V616',\n",
      "       'V621', 'V623', 'V624', 'V625', 'V626', 'V627', 'V628', 'V629', 'V631',\n",
      "       'V632', 'V633A', 'V633B', 'V633C', 'V633D', 'V633E', 'V633F', 'V633G',\n",
      "       'V634', 'V701', 'V702', 'V704', 'V705', 'V714', 'V714A', 'V715', 'V716',\n",
      "       'V717', 'V719', 'V721', 'V729', 'V730', 'V731', 'V732', 'V739', 'V740',\n",
      "       'V741', 'V743A', 'V743B', 'V743C', 'V743D', 'V743E', 'V743F', 'V744A',\n",
      "       'V744B', 'V744C', 'V744D', 'V744E', 'V746'],\n",
      "      dtype='object')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "    print(f\"\\nColumnas disponibles en {df_name}:\\n{df.columns}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we are selecting the desired columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "    selected_columns = df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "    df = df[selected_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we are updating the DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "    dataframes[df_name] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we are filtering the variable labels and values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "    var_labels[var_name] = {var: meta.variable_to_label[var] for var in selected_columns if var in meta.variable_to_label}\n",
    "    value_labels[value_name] = {val: meta.value_labels[val] for val in selected_columns if val in meta.value_labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we are showing the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame rec_3:\n",
      "      ID1              CASEID             V501                  V502  \\\n",
      "0  2019.0        000100201  2           Casado    Actualmente casada   \n",
      "1  2019.0        000102801  2  Viviendo juntos    Actualmente casada   \n",
      "2  2019.0        000102801  6  No viven juntos  Anteriormente casada   \n",
      "3  2019.0        000104801  2  Viviendo juntos    Actualmente casada   \n",
      "4  2019.0        000113601  2  Viviendo juntos    Actualmente casada   \n",
      "\n",
      "             V503           V504 V505 V506  V507    V508  ...  \\\n",
      "0         Una vez  Vive con ella  NaN  NaN   1.0  2008.0  ...   \n",
      "1         Una vez  Vive con ella  NaN  NaN  12.0  2011.0  ...   \n",
      "2         Una vez            NaN  NaN  NaN   8.0  1984.0  ...   \n",
      "3         Una vez  Vive con ella  NaN  NaN  12.0  2009.0  ...   \n",
      "4  Mas de una vez  Vive con ella  NaN  NaN  12.0  2005.0  ...   \n",
      "\n",
      "                             V743C                            V743D  \\\n",
      "0                     Entrevistada  Entrevistada y esposo/compañero   \n",
      "1  Entrevistada y esposo/compañero                     Entrevistada   \n",
      "2                              NaN                              NaN   \n",
      "3                     Entrevistada                     Entrevistada   \n",
      "4                     Entrevistada                     Entrevistada   \n",
      "\n",
      "                             V743E                            V743F V744A  \\\n",
      "0                     Entrevistada                 Esposo/compañero    No   \n",
      "1                     Entrevistada  Entrevistada y esposo/compañero    No   \n",
      "2                              NaN                              NaN    No   \n",
      "3                     Entrevistada                     Entrevistada    No   \n",
      "4  Entrevistada y esposo/compañero                 Esposo/compañero    No   \n",
      "\n",
      "  V744B V744C V744D V744E          V746  \n",
      "0    No    No    No    No    Más que el  \n",
      "1    No    No    No    No  Menos que el  \n",
      "2    No    No    No    No           NaN  \n",
      "3    No    No    No    No           NaN  \n",
      "4    No    No    No    No  Menos que el  \n",
      "\n",
      "[5 rows x 84 columns]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for df_name, df in dataframes.items():\n",
    "    print(f\"\\nDataFrame {df_name}:\\n{df.head()}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Variable Labels new_var_labels3:\n",
      "{'V501': 'labels0', 'V502': 'labels1', 'V503': 'labels2', 'V504': 'labels3', 'V505': 'labels4', 'V506': 'labels5', 'V510': 'labels6', 'V513': 'labels7', 'V525': 'labels8', 'V527': 'labels9', 'V528': 'labels10', 'V529': 'labels11', 'V530': 'labels12', 'V531': 'labels13', 'V532': 'labels14', 'V535': 'labels15', 'V536': 'labels16', 'V537': 'labels17', 'V538': 'labels18', 'V539': 'labels19', 'V540': 'labels20', 'V541': 'labels21', 'V602': 'labels22', 'V603': 'labels23', 'V604': 'labels24', 'V605': 'labels25', 'V613': 'labels26', 'V614': 'labels27', 'V616': 'labels28', 'V621': 'labels29', 'V623': 'labels30', 'V624': 'labels31', 'V625': 'labels32', 'V626': 'labels33', 'V627': 'labels34', 'V628': 'labels35', 'V629': 'labels36', 'V631': 'labels37', 'V632': 'labels38', 'V633A': 'labels39', 'V633B': 'labels40', 'V633C': 'labels41', 'V633D': 'labels42', 'V633E': 'labels43', 'V633F': 'labels44', 'V633G': 'labels45', 'V634': 'labels46', 'V701': 'labels47', 'V702': 'labels48', 'V704': 'labels49', 'V705': 'labels50', 'V714': 'labels51', 'V714A': 'labels52', 'V715': 'labels53', 'V716': 'labels54', 'V717': 'labels55', 'V719': 'labels56', 'V721': 'labels57', 'V729': 'labels58', 'V730': 'labels59', 'V731': 'labels60', 'V732': 'labels61', 'V739': 'labels62', 'V740': 'labels63', 'V741': 'labels64', 'V743A': 'labels65', 'V743B': 'labels66', 'V743C': 'labels67', 'V743D': 'labels68', 'V743E': 'labels69', 'V743F': 'labels70', 'V744A': 'labels71', 'V744B': 'labels72', 'V744C': 'labels73', 'V744D': 'labels74', 'V744E': 'labels75', 'V746': 'labels76'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for var_name, labels in var_labels.items():\n",
    "    print(f\"\\nVariable Labels {var_name}:\\n{labels}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Value Labels new_value_labels3:\n",
      "{}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for value_name, labels in value_labels.items():\n",
    "    print(f\"\\nValue Labels {value_name}:\\n{labels}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Generate a new column for `rec1_1` named as `year`. It should be equal to `2019`. Also, you must update this new variable for the `var_labels` dictionary. Generate a new key for `new_var_labels1` and the value for this key should be **\"Year of the survey\"** **Hint: Use `loc` and `update` method.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Merge `rec1_1`, `rec2_1`, and `rec3_1` using **CASEID**. Name this new object as `endes_2019`. **Hint: Use [this link](https://stackoverflow.com/questions/53645882/pandas-merging-101)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Unify all the `new_var_labels` in one object and `new_value_labels` in another one object. Name these two objects as `var_labels` and `value_labels`. Use them to generate new attributes for `endes_2019`. These attributes should be named as `var_labels` and `value_labels`. **Hint: Use `update` method.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Now, replicate your code of the prevoius sections but for years **2019, 2018, 2017, 2016, 2015**. Import the `REC0111.sav`, `RE223132.sav` and `RE516171.sav` files and their **variables and values labels** from this path `\"../../_data/endes/\"`. For this excersie you must use a for loop. This loop must iterate over **2019, 2018, 2017, 2016, 2015 folders** and import these files. All the files have the same name. You must store these files and their labels in a nested dictionary named as `all_data`. The keys of the dictionary should be named as `year_2019`, for example, and the keys of the nested dictionary should be `data`, `var_labels`, and `value_labels`. **Hint: Use [this link](https://notebooks.githubusercontent.com/view/ipynb?browser=chrome&color_mode=auto&commit=4d6de78e00e7001f16bf6473c2eb7ce24fb611cd&device=unknown_device&enc_url=68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f616c6578616e6465727175697370652f4469706c6f6d61646f5f505543502f346436646537386530306537303031663136626636343733633265623763653234666236313163642f4c6563747572655f342f4c6563747572655f342e6970796e62&logged_in=true&nwo=alexanderquispe%2FDiplomado_PUCP&path=Lecture_4%2FLecture_4.ipynb&platform=windows&repository_id=427747212&repository_type=Repository&version=95#4.2.)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Use `all_data` to append all the data sets. Store all data sets in a list using `for loop`. Then, use `pd.concat` to append all the data sets. Also, you must reset the index to have a good-looking data. This new object should be named as `endes_data_2015_2019`. **Hint: Use [this code](https://stackoverflow.com/questions/32444138/concatenate-a-list-of-pandas-dataframes-together)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Store all the `var_labels` and `value_labels` in a dictionary named as `all_var_labels` and `all_value_labels`. The first keys should be the year for both dictionaries.Then, use them to generate new attributes for `endes_data_2015_2019`. These attributes should be named as `var_labels` and `value_labels`.  **Hint: Use [this link](https://notebooks.githubusercontent.com/view/ipynb?browser=chrome&color_mode=auto&commit=4d6de78e00e7001f16bf6473c2eb7ce24fb611cd&device=unknown_device&enc_url=68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f616c6578616e6465727175697370652f4469706c6f6d61646f5f505543502f346436646537386530306537303031663136626636343733633265623763653234666236313163642f4c6563747572655f342f4c6563747572655f342e6970796e62&logged_in=true&nwo=alexanderquispe%2FDiplomado_PUCP&path=Lecture_4%2FLecture_4.ipynb&platform=windows&repository_id=427747212&repository_type=Repository&version=95#4.2.3.)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Use `endes_data_2015_2019` data to generate a new object named `mean_key_vars` to find the mean of **total children ever born (V201)**, **Ideal number of children (V613)**, **Husbands education-single yrs (V715)**, and **Age at first marriage (V511)** by year and department **(V024)**. Name these columns as **mean_total_children, mean_ideal_children, mean_hb_yr_educ and mean_first_marriage**, respectively. **Hint: Use groupby and [this link](https://stackoverflow.com/questions/40901770/is-there-a-simple-way-to-change-a-column-of-yes-no-to-1-0-in-a-pandas-dataframe).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Merge `mean_key_vars` with `endes_data_2015_2019`. Name this object `final_result`. **Hint: Use merge.**"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
