{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Assignment 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!pip install pyreadstat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!pip install savReaderWriter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import os\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import pyreadstat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rec_1 = pyreadstat.read_sav('/REC0111.sav')\n",
    "\n",
    "print(rec_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rec_2 = pyreadstat.read_sav(r'/RE223132.sav')\n",
    "\n",
    "print(rec_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rec_3 = pyreadstat.read_sav('/RE516171.sav')\n",
    "\n",
    "print(rec_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "file_paths = [\n",
    "    '/REC0111.sav',\n",
    "    '/RE223132.sav',\n",
    "    '/RE516171.sav'\n",
    "]\n",
    "\n",
    "# Define names for imported files and labels\n",
    "file_names = ['rec_1', 'rec_2', 'rec_3']\n",
    "var_labels = ['var_labels1', 'var_labels2', 'var_labels3']\n",
    "value_labels = ['value_labels1', 'value_labels2', 'value_labels3']\n",
    "\n",
    "# Initialize dictionaries to store dataframes and labels\n",
    "dataframes = {}\n",
    "variable_labels = {}\n",
    "value_labels_dict = {}\n",
    "\n",
    "# Loop through the files\n",
    "for i, file_path in enumerate(file_paths):\n",
    "    # Read the SPSS file\n",
    "    df, meta = pyreadstat.read_sav(file_path)\n",
    "\n",
    "    # Store the dataframe\n",
    "    dataframes[file_names[i]] = df\n",
    "\n",
    "    # Store variable labels\n",
    "    variable_labels[var_labels[i]] = meta.column_labels\n",
    "\n",
    "    # Store value labels\n",
    "    value_labels_dict[value_labels[i]] = meta.variable_value_labels\n",
    "\n",
    "# Access the imported data and labels\n",
    "rec_1 = dataframes['rec_1']\n",
    "var_labels1 = variable_labels['var_labels1']\n",
    "value_labels1 = value_labels_dict['value_labels1']\n",
    "\n",
    "rec_2 = dataframes['rec_2']\n",
    "var_labels2 = variable_labels['var_labels2']\n",
    "value_labels2 = value_labels_dict['value_labels2']\n",
    "\n",
    "rec_3 = dataframes['rec_3']\n",
    "var_labels3 = variable_labels['var_labels3']\n",
    "value_labels3 = value_labels_dict['value_labels3']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print (\"rec_1 DataFrame:\")\n",
    "rec_1.head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(\"\\nVariable Labels for rec_1:\")\n",
    "var_labels1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "columns_rec1 = ['CASEID', 'V000', 'V001', 'V002', 'V003', 'V004', 'V007', 'V008', 'V009', 'V010', 'V011', 'V012', 'V024', 'V102', 'V120', 'V121', 'V122', 'V123', 'V124', 'V125', 'V127', 'V133']\n",
    "columns_rec2 = ['CASEID', 'V201', 'V218', 'V301', 'V302', 'V323', 'V323A', 'V325A', 'V326', 'V327', 'V337', 'V359', 'V360', 'V361', 'V362', 'V363', 'V364', 'V367', 'V372', 'V372A', 'V375A', 'V376', 'V376A', 'V379', 'V380']\n",
    "columns_rec3 = ['CASEID', 'V501', 'V502', 'V503', 'V504', 'V505', 'V506', 'V507', 'V508', 'V509', 'V510', 'V511', 'V512', 'V513', 'V525', 'V613', 'V714', 'V715']\n",
    "\n",
    "rec1_1 = rec_1.loc[:, columns_rec1]\n",
    "rec2_1 = rec_2.loc[:, columns_rec2]\n",
    "rec3_1 = rec_3.loc[:, columns_rec3]\n",
    "\n",
    "print (rec1_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print (rec2_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print (rec3_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select columns for rec1\n",
    "selected_columns_rec1 = [\n",
    "    'CASEID', 'V000', 'V001', 'V002', 'V003', 'V004', 'V007', 'V008', 'V009', 'V010',\n",
    "    'V011', 'V012', 'V024', 'V102', 'V120', 'V121', 'V122', 'V123', 'V124', 'V125', 'V127', 'V133'\n",
    "]\n",
    "\n",
    "# Create a new dataframe for rec1 with selected columns\n",
    "rec1_1 = rec_1.loc[:, selected_columns_rec1]\n",
    "\n",
    "# Update the variable labels object for rec1\n",
    "new_var_labels1 = variable_labels['var_labels1'][:len(selected_columns_rec1)]\n",
    "\n",
    "# Update the value labels object for rec1\n",
    "new_value_labels1 = {col: value_labels1.get(col, {}) for col in selected_columns_rec1}\n",
    "\n",
    "# Update the dataframes and labels dictionaries\n",
    "dataframes['rec1_1'] = rec1_1\n",
    "variable_labels['new_var_labels1'] = new_var_labels1\n",
    "value_labels_dict['new_value_labels1'] = new_value_labels1\n",
    "\n",
    "print (rec1_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select columns for rec2\n",
    "selected_columns_rec2 = [\n",
    "    'CASEID', 'V201', 'V218', 'V301', 'V302', 'V323', 'V323A', 'V325A', 'V326', 'V327',\n",
    "    'V337', 'V359', 'V360', 'V361', 'V362', 'V363', 'V364', 'V367', 'V372', 'V372A',\n",
    "    'V375A', 'V376', 'V376A', 'V379', 'V380'\n",
    "]\n",
    "\n",
    "# Create a new dataframe for rec1 with selected columns\n",
    "rec2_1 = rec_2.loc[:, selected_columns_rec2]\n",
    "\n",
    "# Update the variable labels object for rec1\n",
    "new_var_labels2 = variable_labels['var_labels2'][:len(selected_columns_rec2)]\n",
    "\n",
    "# Update the value labels object for rec1\n",
    "new_value_labels2 = {col: value_labels2.get(col, {}) for col in selected_columns_rec2}\n",
    "\n",
    "# Update the dataframes and labels dictionaries\n",
    "dataframes['rec2_1'] = rec2_1\n",
    "variable_labels['new_var_labels2'] = new_var_labels2\n",
    "value_labels_dict['new_value_labels2'] = new_value_labels2\n",
    "\n",
    "print (rec2_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select columns for rec3\n",
    "selected_columns_rec3 = [\n",
    "    'CASEID', 'V501', 'V502', 'V503', 'V504', 'V505', 'V506', 'V507', 'V508', 'V509',\n",
    "    'V510', 'V511', 'V512', 'V513', 'V525', 'V613', 'V714', 'V715'\n",
    "]\n",
    "\n",
    "# Create a new dataframe for rec1 with selected columns\n",
    "rec3_1 = rec_3.loc[:, selected_columns_rec3]\n",
    "\n",
    "# Update the variable labels object for rec1\n",
    "new_var_labels3 = variable_labels['var_labels3'][:len(selected_columns_rec3)]\n",
    "\n",
    "# Update the value labels object for rec1\n",
    "new_value_labels3 = {col: value_labels3.get(col, {}) for col in selected_columns_rec3}\n",
    "\n",
    "# Update the dataframes and labels dictionaries\n",
    "dataframes['rec3_1'] = rec3_1\n",
    "variable_labels['new_var_labels3'] = new_var_labels3\n",
    "value_labels_dict['new_value_labels3'] = new_value_labels3\n",
    "\n",
    "print(rec3_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Generate a new column for rec1_1 named as \"year\"\n",
    "#Use loc to add a column\n",
    "rec1_1.loc[:, 'year'] = 2019\n",
    "\n",
    "# We must update variable labels dictionary\n",
    "new_var_labels1.append({'year': \"Year of the survey\"})\n",
    "\n",
    "print(rec1_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4\n",
    "#merge rec1_1, rec2_1 and rec3_1 using CASEID\n",
    "#use a method chaining to merge the dataframes successively. This for performing a intern joins.\n",
    "endes_2019 = pd.merge(rec1_1, rec2_1, on ='CASEID').merge(rec3_1, on ='CASEID')\n",
    "print(endes_2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "## Exercise 5\n",
    "#Unifing all the new_var_labels in one object and new_value_labels in another one object.\n",
    "var_labels = [new_var_labels1]\n",
    "var_labels.extend(new_var_labels2)\n",
    "var_labels.extend(new_var_labels3)\n",
    "var_labels  \n",
    "\n",
    "\n",
    "\n",
    "#Name these two objects as var_labels and value_labels.\n",
    "value_labels = [new_value_labels1]\n",
    "value_labels.extend(new_value_labels2)\n",
    "value_labels.extend(new_value_labels3)\n",
    "value_labels\n",
    "\n",
    "\n",
    "#Generate new attributes for endes_2019 that is named as var_labels and value_labels.\n",
    "#Using update\n",
    "endes_2019.update({'var_labels': var_labels, 'value_labels': value_labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "## Exercise 6\n",
    "\n",
    "years = [2019, 2018, 2017, 2016, 2015]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "all_data = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "for year in years:\n",
    "\n",
    "    data_path = \"/content\"\n",
    "\n",
    "    rec_1, meta_1 = pyreadstat.read_sav(os.path.join(data_path, '/content/REC0111.sav'))\n",
    "    rec_2, meta_2 = pyreadstat.read_sav(os.path.join(data_path, '/content/RE223132.sav'))\n",
    "    rec_3, meta_3 = pyreadstat.read_sav(os.path.join(data_path, '/content/RE516171.sav'))\n",
    "\n",
    "    columns_1 = ['CASEID', 'V000', 'V001', 'V002', 'V003', 'V004', 'V008', 'V009', 'V010', 'V011', 'V012', 'V024', 'V102', 'V120', 'V121', 'V122', 'V123', 'V124', 'V125', 'V127', 'V133']\n",
    "\n",
    "    rec1_1 = rec_1.loc[:, columns_1]\n",
    "\n",
    "    columns_2 = ['CASEID', 'V201', 'V218', 'V301', 'V302', 'V323', 'V323A', 'V325A', 'V326', 'V327', 'V337', 'V359', 'V360', 'V361', 'V362', 'V363', 'V364', 'V367', 'V372', 'V372A', 'V375A', 'V376', 'V376A', 'V379', 'V380']\n",
    "    rec2_1 = rec_2.loc[:, columns_2]\n",
    "\n",
    "    columns_3 = ['CASEID', 'V501', 'V502', 'V503', 'V504', 'V505', 'V506', 'V507', 'V508', 'V509', 'V510', 'V511', 'V512', 'V513', 'V525', 'V613', 'V714', 'V715']\n",
    "    rec3_1 = rec_3.loc[:, columns_3]\n",
    "\n",
    "    rec1_1.loc[:, 'year'] = year\n",
    "\n",
    "    var_labels = {}\n",
    "    var_labels.update(meta_1.column_names_to_labels)\n",
    "    var_labels.update(meta_2.column_names_to_labels)\n",
    "    var_labels.update(meta_3.column_names_to_labels)\n",
    "\n",
    "\n",
    "    value_labels = {}\n",
    "    value_labels.update(meta_1.variable_value_labels)\n",
    "    value_labels.update(meta_2.variable_value_labels)\n",
    "    value_labels.update(meta_3.variable_value_labels)\n",
    "\n",
    "\n",
    "    endes_data = rec1_1.merge(rec2_1, on='CASEID', how='inner')\n",
    "    endes_data = endes_data.merge(rec3_1, on='CASEID', how='inner')\n",
    "\n",
    "    all_data[f'year_{year}'] = {'data': endes_data, 'var_labels': var_labels, 'value_labels': value_labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#7\n",
    "years = [2019, 2018, 2017, 2016, 2015]\n",
    "#The next step is to create an empty list\n",
    "all_data_sets = []\n",
    "#Now, we append each DataFrame to the list\n",
    "for year_key in all_data:\n",
    "    data_set = all_data[year_key]['data']\n",
    "    all_data_sets.append(data_set)\n",
    "#In order to that, is necessary to use pd.concat to concatenate all the DataFrames in the list\n",
    "endes_data_2015_2019 = pd.concat(all_data_sets, ignore_index=True)\n",
    "endes_data_2015_2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#8\n",
    "all_var_labels = {}\n",
    "all_value_labels = {}\n",
    "#Loop para los diccionarios creados\n",
    "for year_key, year_data in all_data.items():\n",
    "    all_var_labels[year_key] = year_data['var_labels']\n",
    "    all_value_labels[year_key] = year_data['value_labels']\n",
    "#Atribuir valores\n",
    "\n",
    "endes_data_2015_2019.attrs.update({'var_labels': all_var_labels, 'value_labels': all_value_labels})\n",
    "endes_data_2015_2019.attrs['var_labels']"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
