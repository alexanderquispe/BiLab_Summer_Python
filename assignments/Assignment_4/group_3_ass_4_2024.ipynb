{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Assignment 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyreadstat in /Users/claudiaplasenciacustodio/anaconda3/lib/python3.11/site-packages (1.2.5)\n",
      "Requirement already satisfied: pandas>=1.2.0 in /Users/claudiaplasenciacustodio/anaconda3/lib/python3.11/site-packages (from pyreadstat) (2.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/claudiaplasenciacustodio/anaconda3/lib/python3.11/site-packages (from pandas>=1.2.0->pyreadstat) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/claudiaplasenciacustodio/anaconda3/lib/python3.11/site-packages (from pandas>=1.2.0->pyreadstat) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/claudiaplasenciacustodio/anaconda3/lib/python3.11/site-packages (from pandas>=1.2.0->pyreadstat) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /Users/claudiaplasenciacustodio/anaconda3/lib/python3.11/site-packages (from pandas>=1.2.0->pyreadstat) (1.24.3)\n",
      "Requirement already satisfied: six>=1.5 in /Users/claudiaplasenciacustodio/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas>=1.2.0->pyreadstat) (1.16.0)\n"
     ]
    }
   ],

   "source": [
    "!pip install pyreadstat"
   ]
  },
  {

   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!pip install savReaderWriter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},

   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],

   "source": [
    "import os\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",

    "import urllib.request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [

    "import urllib.request\n",

    "import pyreadstat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [

    "rec_1 = pyreadstat.read_sav('/REC0111.sav')\n",
    "\n",
    "print(rec_1)"

    "1. Import the `REC0111.sav`, `RE223132.sav` and `RE516171.sav` files and their variables and values labels from this path `\"../../_data/endes/2019\"`. The name of imported files should be named as `rec_1`, `rec_2` and `rec_3` for files `REC0111.sav`, `RE223132.sav` and `RE516171.sav` respectively. The name of the variable and value labels should be `var_labels1` and `value_labels1` for `rec1`, `var_labels2` and `value_labels2` for `rec2`, and `var_labels3` and `value_labels3` for `rec3`. **Hint: See the section 3.3.4 of [the lecture 3](https://github.com/alexanderquispe/Diplomado_PUCP/blob/main/Lecture_3/Lecture_3.ipynb)**"

   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [

    "rec_2 = pyreadstat.read_sav(r'/RE223132.sav')\n",
    "\n",
    "print(rec_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rec_3 = pyreadstat.read_sav('/RE516171.sav')\n",
    "\n",
    "print(rec_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "file_paths = [\n",
    "    '/REC0111.sav',\n",
    "    '/RE223132.sav',\n",
    "    '/RE516171.sav'\n",
    "]\n",
    "\n",
    "# Define names for imported files and labels\n",
    "file_names = ['rec_1', 'rec_2', 'rec_3']\n",
    "var_labels = ['var_labels1', 'var_labels2', 'var_labels3']\n",
    "value_labels = ['value_labels1', 'value_labels2', 'value_labels3']\n",
    "\n",
    "# Initialize dictionaries to store dataframes and labels\n",
    "dataframes = {}\n",
    "variable_labels = {}\n",
    "value_labels_dict = {}\n",
    "\n",
    "# Loop through the files\n",
    "for i, file_path in enumerate(file_paths):\n",
    "    # Read the SPSS file\n",
    "    df, meta = pyreadstat.read_sav(file_path)\n",
    "\n",
    "    # Store the dataframe\n",
    "    dataframes[file_names[i]] = df\n",
    "\n",
    "    # Store variable labels\n",
    "    variable_labels[var_labels[i]] = meta.column_labels\n",
    "\n",
    "    # Store value labels\n",
    "    value_labels_dict[value_labels[i]] = meta.variable_value_labels\n",
    "\n",
    "# Access the imported data and labels\n",
    "rec_1 = dataframes['rec_1']\n",
    "var_labels1 = variable_labels['var_labels1']\n",
    "value_labels1 = value_labels_dict['value_labels1']\n",
    "\n",
    "rec_2 = dataframes['rec_2']\n",
    "var_labels2 = variable_labels['var_labels2']\n",
    "value_labels2 = value_labels_dict['value_labels2']\n",
    "\n",
    "rec_3 = dataframes['rec_3']\n",
    "var_labels3 = variable_labels['var_labels3']\n",
    "value_labels3 = value_labels_dict['value_labels3']"

    "2. Select the following columns for each data set:\n",
    "|Data|Columns|\n",
    "|---|---|\n",
    "|rec1| CASEID, V000, V001, V002, V003, V004, V007, V008, V009, V010, V011, V012, V024, V102, V120, V121, V122, V123, V124, V125, V127, V133 |\n",
    "|rec2| CASEID, V201, V218, V301, V302, V323, V323A, V325A, V326, V327, V337, V359, V360, V361, V362, V363, V364, V367, V372, V372A, V375A, V376, V376A, V379, V380 |\n",
    "|rec3| CASEID, V501, V502, V503, V504, V505, V506, V507, V508, V509, V510, V511, V512, V513, V525, V613, V714, V715 |\n",
    "\n",
    "\n",
    "Additioanlly, you should update the variables and value labels objects. They must have information only for the selected columns. The new dataframes should be name as `rec1_1`, `rec2_1`, and `rec3_1`. The new varible labels objects should be named as `new_var_labels1`, `new_var_labels2`, and `new_var_labels3`. The new value labels objects should be named as `new_value_labels1`, `new_value_labels2`, and `new_value_labels3` **Hint: Use the `loc` and column names to filter, `for loop`,   and [this link](https://stackoverflow.com/questions/3420122/filter-dict-to-contain-only-certain-keys) to update the var and value dictionary.**"

   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print (\"rec_1 DataFrame:\")\n",
    "rec_1.head"
    "3. Generate a new column for `rec1_1` named as `year`. It should be equal to `2019`. Also, you must update this new variable for the `var_labels` dictionary. Generate a new key for `new_var_labels1` and the value for this key should be **\"Year of the survey\"** **Hint: Use `loc` and `update` method.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(\"\\nVariable Labels for rec_1:\")\n",
    "var_labels1"
    "4. Merge `rec1_1`, `rec2_1`, and `rec3_1` using **CASEID**. Name this new object as `endes_2019`. **Hint: Use [this link](https://stackoverflow.com/questions/53645882/pandas-merging-101)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "columns_rec1 = ['CASEID', 'V000', 'V001', 'V002', 'V003', 'V004', 'V007', 'V008', 'V009', 'V010', 'V011', 'V012', 'V024', 'V102', 'V120', 'V121', 'V122', 'V123', 'V124', 'V125', 'V127', 'V133']\n",
    "columns_rec2 = ['CASEID', 'V201', 'V218', 'V301', 'V302', 'V323', 'V323A', 'V325A', 'V326', 'V327', 'V337', 'V359', 'V360', 'V361', 'V362', 'V363', 'V364', 'V367', 'V372', 'V372A', 'V375A', 'V376', 'V376A', 'V379', 'V380']\n",
    "columns_rec3 = ['CASEID', 'V501', 'V502', 'V503', 'V504', 'V505', 'V506', 'V507', 'V508', 'V509', 'V510', 'V511', 'V512', 'V513', 'V525', 'V613', 'V714', 'V715']\n",
    "\n",
    "rec1_1 = rec_1.loc[:, columns_rec1]\n",
    "rec2_1 = rec_2.loc[:, columns_rec2]\n",
    "rec3_1 = rec_3.loc[:, columns_rec3]\n",
    "\n",
    "print (rec1_1)"
    "5. Unify all the `new_var_labels` in one object and `new_value_labels` in another one object. Name these two objects as `var_labels` and `value_labels`. Use them to generate new attributes for `endes_2019`. These attributes should be named as `var_labels` and `value_labels`. **Hint: Use `update` method.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print (rec2_1)"
    "6. Now, replicate your code of the prevoius sections but for years **2019, 2018, 2017, 2016, 2015**. Import the `REC0111.sav`, `RE223132.sav` and `RE516171.sav` files and their **variables and values labels** from this path `\"../../_data/endes/\"`. For this excersie you must use a for loop. This loop must iterate over **2019, 2018, 2017, 2016, 2015 folders** and import these files. All the files have the same name. You must store these files and their labels in a nested dictionary named as `all_data`. The keys of the dictionary should be named as `year_2019`, for example, and the keys of the nested dictionary should be `data`, `var_labels`, and `value_labels`. **Hint: Use [this link](https://notebooks.githubusercontent.com/view/ipynb?browser=chrome&color_mode=auto&commit=4d6de78e00e7001f16bf6473c2eb7ce24fb611cd&device=unknown_device&enc_url=68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f616c6578616e6465727175697370652f4469706c6f6d61646f5f505543502f346436646537386530306537303031663136626636343733633265623763653234666236313163642f4c6563747572655f342f4c6563747572655f342e6970796e62&logged_in=true&nwo=alexanderquispe%2FDiplomado_PUCP&path=Lecture_4%2FLecture_4.ipynb&platform=windows&repository_id=427747212&repository_type=Repository&version=95#4.2.)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print (rec3_1)"
    "7. Use `all_data` to append all the data sets. Store all data sets in a list using `for loop`. Then, use `pd.concat` to append all the data sets. Also, you must reset the index to have a good-looking data. This new object should be named as `endes_data_2015_2019`. **Hint: Use [this code](https://stackoverflow.com/questions/32444138/concatenate-a-list-of-pandas-dataframes-together)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select columns for rec1\n",
    "selected_columns_rec1 = [\n",
    "    'CASEID', 'V000', 'V001', 'V002', 'V003', 'V004', 'V007', 'V008', 'V009', 'V010',\n",
    "    'V011', 'V012', 'V024', 'V102', 'V120', 'V121', 'V122', 'V123', 'V124', 'V125', 'V127', 'V133'\n",
    "]\n",
    "\n",
    "# Create a new dataframe for rec1 with selected columns\n",
    "rec1_1 = rec_1.loc[:, selected_columns_rec1]\n",
    "\n",
    "# Update the variable labels object for rec1\n",
    "new_var_labels1 = variable_labels['var_labels1'][:len(selected_columns_rec1)]\n",
    "\n",
    "# Update the value labels object for rec1\n",
    "new_value_labels1 = {col: value_labels1.get(col, {}) for col in selected_columns_rec1}\n",
    "\n",
    "# Update the dataframes and labels dictionaries\n",
    "dataframes['rec1_1'] = rec1_1\n",
    "variable_labels['new_var_labels1'] = new_var_labels1\n",
    "value_labels_dict['new_value_labels1'] = new_value_labels1\n",
    "\n",
    "print (rec1_1)"
    "8. Store all the `var_labels` and `value_labels` in a dictionary named as `all_var_labels` and `all_value_labels`. The first keys should be the year for both dictionaries.Then, use them to generate new attributes for `endes_data_2015_2019`. These attributes should be named as `var_labels` and `value_labels`.  **Hint: Use [this link](https://notebooks.githubusercontent.com/view/ipynb?browser=chrome&color_mode=auto&commit=4d6de78e00e7001f16bf6473c2eb7ce24fb611cd&device=unknown_device&enc_url=68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f616c6578616e6465727175697370652f4469706c6f6d61646f5f505543502f346436646537386530306537303031663136626636343733633265623763653234666236313163642f4c6563747572655f342f4c6563747572655f342e6970796e62&logged_in=true&nwo=alexanderquispe%2FDiplomado_PUCP&path=Lecture_4%2FLecture_4.ipynb&platform=windows&repository_id=427747212&repository_type=Repository&version=95#4.2.3.)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select columns for rec2\n",
    "selected_columns_rec2 = [\n",
    "    'CASEID', 'V201', 'V218', 'V301', 'V302', 'V323', 'V323A', 'V325A', 'V326', 'V327',\n",
    "    'V337', 'V359', 'V360', 'V361', 'V362', 'V363', 'V364', 'V367', 'V372', 'V372A',\n",
    "    'V375A', 'V376', 'V376A', 'V379', 'V380'\n",
    "]\n",
    "\n",
    "# Create a new dataframe for rec1 with selected columns\n",
    "rec2_1 = rec_2.loc[:, selected_columns_rec2]\n",
    "\n",
    "# Update the variable labels object for rec1\n",
    "new_var_labels2 = variable_labels['var_labels2'][:len(selected_columns_rec2)]\n",
    "\n",
    "# Update the value labels object for rec1\n",
    "new_value_labels2 = {col: value_labels2.get(col, {}) for col in selected_columns_rec2}\n",
    "\n",
    "# Update the dataframes and labels dictionaries\n",
    "dataframes['rec2_1'] = rec2_1\n",
    "variable_labels['new_var_labels2'] = new_var_labels2\n",
    "value_labels_dict['new_value_labels2'] = new_value_labels2\n",
    "\n",
    "print (rec2_1)"
    "9. Use `endes_data_2015_2019` data to generate a new object named `mean_key_vars` to find the mean of **total children ever born (V201)**, **Ideal number of children (V613)**, **Husbands education-single yrs (V715)**, and **Age at first marriage (V511)** by year and department **(V024)**. Name these columns as **mean_total_children, mean_ideal_children, mean_hb_yr_educ and mean_first_marriage**, respectively. **Hint: Use groupby and [this link](https://stackoverflow.com/questions/40901770/is-there-a-simple-way-to-change-a-column-of-yes-no-to-1-0-in-a-pandas-dataframe).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select columns for rec3\n",
    "selected_columns_rec3 = [\n",
    "    'CASEID', 'V501', 'V502', 'V503', 'V504', 'V505', 'V506', 'V507', 'V508', 'V509',\n",
    "    'V510', 'V511', 'V512', 'V513', 'V525', 'V613', 'V714', 'V715'\n",
    "]\n",
    "\n",
    "# Create a new dataframe for rec1 with selected columns\n",
    "rec3_1 = rec_3.loc[:, selected_columns_rec3]\n",
    "\n",
    "# Update the variable labels object for rec1\n",
    "new_var_labels3 = variable_labels['var_labels3'][:len(selected_columns_rec3)]\n",
    "\n",
    "# Update the value labels object for rec1\n",
    "new_value_labels3 = {col: value_labels3.get(col, {}) for col in selected_columns_rec3}\n",
    "\n",
    "# Update the dataframes and labels dictionaries\n",
    "dataframes['rec3_1'] = rec3_1\n",
    "variable_labels['new_var_labels3'] = new_var_labels3\n",
    "value_labels_dict['new_value_labels3'] = new_value_labels3\n",
    "\n",
    "print(rec3_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Generate a new column for rec1_1 named as \"year\"\n",
    "#Use loc to add a column\n",
    "rec1_1.loc[:, 'year'] = 2019\n",
    "\n",
    "# We must update variable labels dictionary\n",
    "new_var_labels1.append({'year': \"Year of the survey\"})\n",
    "\n",
    "print(rec1_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4\n",
    "#merge rec1_1, rec2_1 and rec3_1 using CASEID\n",
    "#use a method chaining to merge the dataframes successively. This for performing a intern joins.\n",
    "endes_2019 = pd.merge(rec1_1, rec2_1, on ='CASEID').merge(rec3_1, on ='CASEID')\n",
    "print(endes_2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "## Exercise 5\n",
    "#Unifing all the new_var_labels in one object and new_value_labels in another one object.\n",
    "var_labels = [new_var_labels1]\n",
    "var_labels.extend(new_var_labels2)\n",
    "var_labels.extend(new_var_labels3)\n",
    "var_labels  \n",
    "\n",
    "\n",
    "\n",
    "#Name these two objects as var_labels and value_labels.\n",
    "value_labels = [new_value_labels1]\n",
    "value_labels.extend(new_value_labels2)\n",
    "value_labels.extend(new_value_labels3)\n",
    "value_labels\n",
    "\n",
    "\n",
    "#Generate new attributes for endes_2019 that is named as var_labels and value_labels.\n",
    "#Using update\n",
    "endes_2019.update({'var_labels': var_labels, 'value_labels': value_labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "## Exercise 6\n",
    "\n",
    "years = [2019, 2018, 2017, 2016, 2015]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "all_data = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "for year in years:\n",
    "\n",
    "    data_path = \"/content\"\n",
    "\n",
    "    rec_1, meta_1 = pyreadstat.read_sav(os.path.join(data_path, '/content/REC0111.sav'))\n",
    "    rec_2, meta_2 = pyreadstat.read_sav(os.path.join(data_path, '/content/RE223132.sav'))\n",
    "    rec_3, meta_3 = pyreadstat.read_sav(os.path.join(data_path, '/content/RE516171.sav'))\n",
    "\n",
    "    columns_1 = ['CASEID', 'V000', 'V001', 'V002', 'V003', 'V004', 'V008', 'V009', 'V010', 'V011', 'V012', 'V024', 'V102', 'V120', 'V121', 'V122', 'V123', 'V124', 'V125', 'V127', 'V133']\n",
    "\n",
    "    rec1_1 = rec_1.loc[:, columns_1]\n",
    "\n",
    "    columns_2 = ['CASEID', 'V201', 'V218', 'V301', 'V302', 'V323', 'V323A', 'V325A', 'V326', 'V327', 'V337', 'V359', 'V360', 'V361', 'V362', 'V363', 'V364', 'V367', 'V372', 'V372A', 'V375A', 'V376', 'V376A', 'V379', 'V380']\n",
    "    rec2_1 = rec_2.loc[:, columns_2]\n",
    "\n",
    "    columns_3 = ['CASEID', 'V501', 'V502', 'V503', 'V504', 'V505', 'V506', 'V507', 'V508', 'V509', 'V510', 'V511', 'V512', 'V513', 'V525', 'V613', 'V714', 'V715']\n",
    "    rec3_1 = rec_3.loc[:, columns_3]\n",
    "\n",
    "    rec1_1.loc[:, 'year'] = year\n",
    "\n",
    "    var_labels = {}\n",
    "    var_labels.update(meta_1.column_names_to_labels)\n",
    "    var_labels.update(meta_2.column_names_to_labels)\n",
    "    var_labels.update(meta_3.column_names_to_labels)\n",
    "\n",
    "\n",
    "    value_labels = {}\n",
    "    value_labels.update(meta_1.variable_value_labels)\n",
    "    value_labels.update(meta_2.variable_value_labels)\n",
    "    value_labels.update(meta_3.variable_value_labels)\n",
    "\n",
    "\n",
    "    endes_data = rec1_1.merge(rec2_1, on='CASEID', how='inner')\n",
    "    endes_data = endes_data.merge(rec3_1, on='CASEID', how='inner')\n",
    "\n",
    "    all_data[f'year_{year}'] = {'data': endes_data, 'var_labels': var_labels, 'value_labels': value_labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#7\n",
    "years = [2019, 2018, 2017, 2016, 2015]\n",
    "#The next step is to create an empty list\n",
    "all_data_sets = []\n",
    "#Now, we append each DataFrame to the list\n",
    "for year_key in all_data:\n",
    "    data_set = all_data[year_key]['data']\n",
    "    all_data_sets.append(data_set)\n",
    "#In order to that, is necessary to use pd.concat to concatenate all the DataFrames in the list\n",
    "endes_data_2015_2019 = pd.concat(all_data_sets, ignore_index=True)\n",
    "endes_data_2015_2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#8\n",
    "all_var_labels = {}\n",
    "all_value_labels = {}\n",
    "#Loop para los diccionarios creados\n",
    "for year_key, year_data in all_data.items():\n",
    "    all_var_labels[year_key] = year_data['var_labels']\n",
    "    all_value_labels[year_key] = year_data['value_labels']\n",
    "#Atribuir valores\n",
    "\n",
    "endes_data_2015_2019.attrs.update({'var_labels': all_var_labels, 'value_labels': all_value_labels})\n",
    "endes_data_2015_2019.attrs['var_labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#9\n",
    "key_vars = [\"V201\", \"V613\", \"V715\", \"V511\"]\n",
    "#Agrupar DataFrame por \"year\" and \"department\" \n",
    "mean_key_vars = endes_data_2015_2019.groupby([\"year\", \"V024\"])[key_vars].mean().reset_index()\n",
    "#Luego, calcular columnas especiales\n",
    "mean_key_vars = mean_key_vars.round(2)\n",
    "#Renombrarlas\n",
    "mean_key_vars = mean_key_vars.rename(columns={\"V201\": \"mean_total_children\",\"V613\": \"mean_ideal_children\",\"V715\": \"mean_hb_yr_educ\",\"V511\":\"mean_first_marriage\"})\n",
    "mean_key_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#10\n",
    "endes_data_2015_2019 = endes_data_2015_2019.rename(columns={'V024': 'dpto'})\n",
    "#First, identify the common columns for merging\n",
    "mean_key_vars = mean_key_vars.rename(columns={'V024': 'dpto'})\n",
    "#We use merge to combine the DataFrames\n",
    "final_result = pd.merge(endes_data_2015_2019, mean_key_vars, on=['year', 'dpto'], how='left')\n",
    "final_result"
    "10. Merge `mean_key_vars` with `endes_data_2015_2019`. Name this object `final_result`. **Hint: Use merge.**"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
